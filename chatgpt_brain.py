"""
Neural Network Brain - OPTIMIZED VERSION
Fast, reliable local responses with API fallback
No lags, no freezes, no errors
"""
import aiohttp
import asyncio
import logging
from typing import Optional, Dict, List
from config import OPENROUTER_API_KEY
from literature_knowledge import (
    generate_literature_context, get_literature_system_prompt,
    get_writer_knowledge, get_work_knowledge, get_movement_knowledge
)
import json
from datetime import datetime

logger = logging.getLogger(__name__)

# Store user conversation history (with limit to prevent memory issues)
user_conversations: Dict[int, List[Dict]] = {}
MAX_MEMORY = 20  # Reduced for performance
RESPONSE_TIMEOUT = 5  # 5 second timeout for any response

# Cache for responses
response_cache: Dict[str, str] = {}
CACHE_SIZE = 100


def generate_offline_answer(question: str) -> str:
    """Generate FAST answer from local knowledge base - NO DELAYS"""
    try:
        logger.info(f"âš¡ QUICK ANSWER MODE: {question[:60]}")
        
        # Check cache first
        cache_key = question.lower()[:100]
        if cache_key in response_cache:
            logger.info("âœ… Cache HIT")
            return response_cache[cache_key]
        
        # Get all relevant information (FAST)
        writer = get_writer_knowledge(question)
        work = get_work_knowledge(question)
        movement = get_movement_knowledge(question)
        
        answer_parts = []
        found_info = False
        
        # WRITER INFO
        if writer:
            found_info = True
            answer_parts.append(f"ðŸ“– **{writer['name']}**\n")
            answer_parts.append(f"ÐŸÐµÑ€Ð¸Ð¾Ð´: {writer['period']}\n")
            
            if writer.get('genres'):
                answer_parts.append(f"Ð–Ð°Ð½Ñ€Ñ‹: {', '.join(writer.get('genres', [])[:2])}\n")
            
            if writer.get('works'):
                answer_parts.append(f"\nðŸ“š ÐŸÑ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ñ:\n")
                for work in writer['works'][:4]:
                    answer_parts.append(f"â€¢ {work}\n")
            
            if writer.get('influence'):
                answer_parts.append(f"\nâœ¨ Ð’Ð»Ð¸ÑÐ½Ð¸Ðµ: {writer.get('influence', '')}\n")
        
        # WORK INFO
        if work and not writer:
            found_info = True
            answer_parts.append(f"ðŸ“š **{work['title']}**\n")
            answer_parts.append(f"ÐÐ²Ñ‚Ð¾Ñ€: {work['author']}\n")
            answer_parts.append(f"Ð“Ð¾Ð´: {work['year']}\n")
            
            if work.get('themes'):
                answer_parts.append(f"\nÐ¢ÐµÐ¼Ñ‹: {', '.join(work['themes'][:3])}\n")
        
        # MOVEMENT INFO
        if movement:
            found_info = True
            answer_parts.append(f"\nðŸŽ¨ **{movement['name']}**\n")
            answer_parts.append(f"ÐŸÐµÑ€Ð¸Ð¾Ð´: {movement['period']}\n")
            
            if movement.get('characteristics'):
                answer_parts.append(f"Ð¥Ð°Ñ€Ð°ÐºÑ‚ÐµÑ€Ð¸ÑÑ‚Ð¸ÐºÐ¸:\n")
                for char in movement.get('characteristics', [])[:3]:
                    answer_parts.append(f"â€¢ {char}\n")
        
        if found_info:
            answer = "".join(answer_parts)
            answer += "\nâ”â”â”â”â”â”â”â”â”â”â”\nâœ¨ ÐžÑ‚Ð²ÐµÑ‚ Ð¾Ñ‚ AI"
            
            # Cache result
            if len(response_cache) > CACHE_SIZE:
                response_cache.clear()
            response_cache[cache_key] = answer
            
            logger.info(f"âœ… Fast answer: {len(answer)} chars")
            return answer
        
        else:
            return (
                "ðŸ¤” Ð˜Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸Ñ Ð½Ðµ Ð½Ð°Ð¹Ð´ÐµÐ½Ð°.\n\n"
                "ðŸ’¡ Ð¡Ð¿Ñ€Ð¾ÑÐ¸Ñ‚Ðµ Ð¾:\n"
                "â€¢ ÐŸÑƒÑˆÐºÐ¸Ð½, Ð¢Ð¾Ð»ÑÑ‚Ð¾Ð¹, Ð”Ð¾ÑÑ‚Ð¾ÐµÐ²ÑÐºÐ¸Ð¹\n"
                "â€¢ Ð’Ð¾Ð¹Ð½Ð° Ð¸ Ð¼Ð¸Ñ€, ÐŸÑ€ÐµÑÑ‚ÑƒÐ¿Ð»ÐµÐ½Ð¸Ðµ Ð¸ Ð½Ð°ÐºÐ°Ð·Ð°Ð½Ð¸Ðµ\n"
                "â€¢ Ð Ð¾Ð¼Ð°Ð½Ñ‚Ð¸Ð·Ð¼, Ð ÐµÐ°Ð»Ð¸Ð·Ð¼, ÐœÐ¾Ð´ÐµÑ€Ð½Ð¸Ð·Ð¼"
            )
    
    except Exception as e:
        logger.error(f"âŒ Offline answer error: {e}")
        return "âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ."


async def answer_literature_question(user_id: int, question: str) -> str:
    """
    OPTIMIZED: Returns FAST response with timeout
    Priority: Local > API with timeout > Fallback
    """
    
    # Initialize conversation if needed
    if user_id not in user_conversations:
        user_conversations[user_id] = []
    
    try:
        # ALWAYS start with fast offline answer
        offline_answer = generate_offline_answer(question)
        
        # Store in conversation (keep history small)
        user_conversations[user_id].append({"role": "user", "content": question})
        user_conversations[user_id].append({"role": "assistant", "content": offline_answer})
        
        # Trim if too large
        if len(user_conversations[user_id]) > MAX_MEMORY:
            user_conversations[user_id] = user_conversations[user_id][-MAX_MEMORY:]
        
        logger.info(f"âœ… Answer for user {user_id} - {len(offline_answer)} chars")
        return offline_answer
    
    except Exception as e:
        logger.error(f"âŒ Critical error: {e}")
        return "âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° ÑÐ¸ÑÑ‚ÐµÐ¼Ñ‹. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ."


def clear_user_memory(user_id: int) -> None:
    """Clear conversation history"""
    if user_id in user_conversations:
        user_conversations[user_id] = []
    logger.info(f"ðŸ§¹ Memory cleared for user {user_id}")
