"""
Neural Network Brain - Claude 3.5 Sonnet Integration
Integrates with OpenRouter API for autonomous literary analysis
Enhanced with comprehensive literature knowledge base
Fallback: Local knowledge base when API is unavailable
"""
import aiohttp
import logging
from typing import Optional, Dict, List
from config import OPENROUTER_API_KEY
from literature_knowledge import (
    generate_literature_context, get_literature_system_prompt,
    get_writer_knowledge, get_work_knowledge, get_movement_knowledge
)
import json
from datetime import datetime

logger = logging.getLogger(__name__)

# Store user conversation history
user_conversations: Dict[int, List[Dict]] = {}
MAX_MEMORY = 30  # Maximum messages to remember per user

def analyze_question_type(question: str) -> Dict:
    """Analyze question to determine what type of information is needed"""
    q_lower = question.lower()
    
    analysis = {
        'type': None,
        'is_about_first': False,
        'is_biographical': False,
        'is_comparative': False,
        'is_about_themes': False,
        'is_about_quotes': False,
        'is_about_style': False,
    }
    
    # Detect question type
    first_keywords = ['Ð¿ÐµÑ€Ð²Ð¾Ðµ', 'first', 'dÃ©but', 'Ð½Ð°Ñ‡Ð°Ð»', 'earliest', 'ÑÐ°Ð¼Ð¾Ðµ Ñ€Ð°Ð½Ð½ÐµÐµ']
    bio_keywords = ['ÐºÐ¾Ð³Ð´Ð°', 'when', 'Ð³Ð´Ðµ', 'where', 'Ð¶Ð¸Ð»', 'lived', 'Ñ€Ð¾Ð¶Ð´', 'born', 'ÑƒÐ¼ÐµÑ€', 'died', 'Ð±Ð¸Ð¾Ð³Ñ€Ð°Ñ„Ð¸Ñ', 'biography']
    compare_keywords = ['Ð¾Ñ‚Ð»Ð¸Ñ‡Ð¸Ðµ', 'difference', 'ÑÑ€Ð°Ð²Ð½', 'compare', 'Ñ€Ð°Ð·Ð½Ð¸Ñ†Ð°', 'vs', 'versus', 'Ð¸Ð»Ð¸', 'or']
    theme_keywords = ['Ñ‚ÐµÐ¼Ð°', 'theme', 'ÑÐ¼Ñ‹ÑÐ»', 'meaning', 'Ð¾ Ñ‡Ñ‘Ð¼', 'what about', 'Ð³Ð»Ð°Ð²Ð½Ð¾Ðµ', 'Ð³Ð»Ð°Ð²Ð½Ð°Ñ Ð¸Ð´ÐµÑ', 'main idea']
    quote_keywords = ['Ñ†Ð¸Ñ‚Ð°Ñ‚Ð°', 'quote', 'ÑÐºÐ°Ð·Ð°Ð»', 'said', 'ÑÐ»Ð¾Ð²Ð°', 'words', 'Ð²Ñ‹ÑÐºÐ°Ð·', 'Ñ„Ñ€Ð°Ð·Ð°', 'phrase']
    style_keywords = ['ÑÑ‚Ð¸Ð»ÑŒ', 'style', 'Ñ‚ÐµÑ…Ð½Ð¸ÐºÐ°', 'technique', 'Ð¿Ð¸ÑÐ°Ð»', 'wrote', 'Ð¼Ð°Ð½ÐµÑ€Ð°', 'manner', 'Ð¶Ð°Ð½Ñ€', 'genre']
    
    if any(kw in q_lower for kw in first_keywords):
        analysis['is_about_first'] = True
    if any(kw in q_lower for kw in bio_keywords):
        analysis['is_biographical'] = True
    if any(kw in q_lower for kw in compare_keywords):
        analysis['is_comparative'] = True
    if any(kw in q_lower for kw in theme_keywords):
        analysis['is_about_themes'] = True
    if any(kw in q_lower for kw in quote_keywords):
        analysis['is_about_quotes'] = True
    if any(kw in q_lower for kw in style_keywords):
        analysis['is_about_style'] = True
    
    return analysis

def generate_offline_answer(question: str) -> str:
    """Generate accurate answer from local knowledge base with neural network quality"""
    try:
        logger.info(f"ðŸ§  ANALYZING QUESTION: {question[:80]}")
        
        # Analyze question to determine information needs
        analysis = analyze_question_type(question)
        logger.info(f"ðŸ” ANALYSIS: {analysis}")
        
        # Get all relevant information
        writer = get_writer_knowledge(question)
        work = get_work_knowledge(question)
        movement = get_movement_knowledge(question)
        
        answer_parts = []
        found_info = False
        
        # ============ WRITER-FOCUSED ANSWERS ============
        if writer:
            found_info = True
            logger.info(f"ðŸ“– Found writer: {writer['name']}")
            
            # Main header
            answer_parts.append(f"ðŸ“– **{writer['name']}**\n")
            answer_parts.append(f"Period: {writer['period']}\n")
            
            # Biographical information if requested
            if analysis['is_biographical']:
                answer_parts.append(f"\nðŸ›ï¸ **BIOGRAPHICAL CONTEXT**\n")
                answer_parts.append(f"Active in: {writer['period']}\n")
                answer_parts.append(f"Key genres: {', '.join(writer.get('genres', ['Literary Fiction']))}\n")
                answer_parts.append(f"Influence: {writer.get('influence', 'Major contributor to literature')}\n")
            
            # Works section
            answer_parts.append(f"\nðŸ“š **MAJOR WORKS**\n")
            if analysis['is_about_first'] and writer.get('works'):
                answer_parts.append(f"First work: **{writer['works'][0]}**\n")
                answer_parts.append(f"Other notable works: {', '.join(writer['works'][1:4])}\n")
            else:
                # Show top works with description
                all_works = writer.get('works', [])[:8]
                answer_parts.append(f"Notable works: {', '.join(all_works)}\n")
            
            # Themes and style if requested
            if analysis['is_about_themes'] or analysis['is_about_style']:
                answer_parts.append(f"\nðŸŽ­ **LITERARY STYLE & THEMES**\n")
                answer_parts.append(f"Genres: {', '.join(writer.get('genres', ['Literary Fiction']))}\n")
                answer_parts.append(f"Literary influence: {writer.get('influence', 'Significant contribution to literature')}\n")
            
            # Quotes section
            if analysis['is_about_quotes'] or not analysis['is_about_first']:
                answer_parts.append(f"\nðŸ’­ **NOTABLE QUOTES**\n")
                if writer.get('quotes'):
                    for i, quote in enumerate(writer.get('quotes', [])[:3], 1):
                        answer_parts.append(f"{i}. \"{quote}\"\n")
        
        # ============ WORK-FOCUSED ANSWERS ============
        if work:
            found_info = True
            logger.info(f"ðŸ“š Found work: {work['title']}")
            
            if not writer:  # If not already added from writer
                answer_parts.append(f"ðŸ“š **{work['title']}**\n")
            else:
                answer_parts.append(f"\n### Detailed Analysis: {work['title']}\n")
            
            answer_parts.append(f"Author: {work['author']}\n")
            answer_parts.append(f"Year: {work['year']}\n")
            answer_parts.append(f"Genre: {work.get('genre', 'Literary Fiction')}\n")
            
            # Themes
            if work.get('themes'):
                answer_parts.append(f"\n**Central Themes:**\n")
                for theme in work['themes']:
                    answer_parts.append(f"â€¢ {theme}\n")
            
            # Quotes from work
            if work.get('quotes'):
                answer_parts.append(f"\n**Famous Quotes from the work:**\n")
                for quote in work.get('quotes', [])[:2]:
                    answer_parts.append(f"\"{quote}\"\n")
        
        # ============ MOVEMENT-FOCUSED ANSWERS ============
        if movement:
            found_info = True
            logger.info(f"ðŸŽ¨ Found movement: {movement['name']}")
            
            answer_parts.append(f"\nðŸŽ¨ **LITERARY MOVEMENT: {movement['name'].upper()}**\n")
            answer_parts.append(f"Period: {movement['period']}\n")
            
            answer_parts.append(f"\n**Characteristics:**\n")
            for char in movement.get('characteristics', [])[:5]:
                answer_parts.append(f"â€¢ {char}\n")
            
            if movement.get('key_authors'):
                answer_parts.append(f"\n**Key Authors:** {', '.join(movement['key_authors'])}\n")
        
        if found_info:
            answer = "".join(answer_parts)
            answer += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\nâœ¨ *ÐžÑ‚Ð²ÐµÑ‚ Ð¾Ñ‚ AI Neural Network*"
            logger.info(f"âœ… Offline answer generated ({len(answer)} chars)")
            return answer
        else:
            logger.warning(f"âŒ No information found for: {question}")
            return (
                "ðŸ¤” Ðš ÑÐ¾Ð¶Ð°Ð»ÐµÐ½Ð¸ÑŽ, Ñ Ð½Ðµ ÑÐ¼Ð¾Ð³ Ð½Ð°Ð¹Ñ‚Ð¸ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¿Ð¾ Ð²Ð°ÑˆÐµÐ¼Ñƒ Ð·Ð°Ð¿Ñ€Ð¾ÑÑƒ.\n\n"
                "ðŸ’¡ ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ:\n"
                "â€¢ ÐŸÐµÑ€ÐµÑ„Ð¾Ñ€Ð¼ÑƒÐ»Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ\n"
                "â€¢ Ð¡Ð¿Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð¾ Ð¸Ð·Ð²ÐµÑÑ‚Ð½Ð¾Ð¼ Ð°Ð²Ñ‚Ð¾Ñ€Ðµ (ÐŸÑƒÑˆÐºÐ¸Ð½, Ð¢Ð¾Ð»ÑÑ‚Ð¾Ð¹, Ð”Ð¾ÑÑ‚Ð¾ÐµÐ²ÑÐºÐ¸Ð¹)\n"
                "â€¢ Ð¡Ð¿Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð¾ Ð¿Ð¾Ð¿ÑƒÐ»ÑÑ€Ð½Ð¾Ð¼ Ð¿Ñ€Ð¾Ð¸Ð·Ð²ÐµÐ´ÐµÐ½Ð¸Ð¸ (Ð’Ð¾Ð¹Ð½Ð° Ð¸ Ð¼Ð¸Ñ€, Crime and Punishment)\n"
                "â€¢ Ð¡Ð¿Ñ€Ð¾ÑÐ¸Ñ‚ÑŒ Ð¾ Ð»Ð¸Ñ‚ÐµÑ€Ð°Ñ‚ÑƒÑ€Ð½Ð¾Ð¼ Ð´Ð²Ð¸Ð¶ÐµÐ½Ð¸Ð¸ (Ð Ð¾Ð¼Ð°Ð½Ñ‚Ð¸Ð·Ð¼, Ð ÐµÐ°Ð»Ð¸Ð·Ð¼)"
            )
    
    except Exception as e:
        logger.error(f"âŒ Error generating offline answer: {e}", exc_info=True)
        return "âš ï¸ ÐÐµ ÑƒÐ´Ð°Ð»Ð¾ÑÑŒ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚Ð°Ñ‚ÑŒ Ð²Ð¾Ð¿Ñ€Ð¾Ñ. ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐ¹Ñ‚Ðµ Ð¿Ð¾Ð·Ð¶Ðµ."

async def get_wikipedia_context(query: str) -> str:
    """Fetch context from Wikipedia using aiohttp"""
    try:
        async with aiohttp.ClientSession() as session:
            params = {
                'action': 'query',
                'format': 'json',
                'titles': query,
                'prop': 'extracts',
                'exintro': 1,
                'explaintext': 1,
                'redirects': 1
            }
            
            async with session.get('https://en.wikipedia.org/w/api.php', params=params) as resp:
                if resp.status == 200:
                    data = await resp.json()
                    pages = data.get('query', {}).get('pages', {})
                    for page_id, page_data in pages.items():
                        if page_id != '-1':
                            extract = page_data.get('extract', '')
                            if extract:
                                return extract[:1000]  # Limit to 1000 chars
    except Exception as e:
        logger.warning(f"Wikipedia fetch error: {e}")
    
    return ""

async def answer_literature_question(user_id: int, question: str) -> str:
    """
    Main neural network function - uses Claude 3.5 Sonnet for answering
    literature questions with Wikipedia context
    """
    
    if not OPENROUTER_API_KEY:
        logger.error("OPENROUTER_API_KEY not set")
        return "âš ï¸ API configuration error. Please contact administrator."
    
    # Initialize user conversation if needed
    if user_id not in user_conversations:
        user_conversations[user_id] = []
    
    try:
        # Get Wikipedia context for better answers
        wikipedia_context = await get_wikipedia_context(question)
        
        # Build conversation history for context
        conversation_history = user_conversations[user_id][-10:]  # Last 10 messages for context
        
        # Build messages for Claude
        messages = []
        
        # Add conversation history
        for msg in conversation_history:
            messages.append(msg)
        
        # Add current question with Wikipedia context
        context_text = ""
        if wikipedia_context:
            context_text = f"\n\nðŸ“š Wikipedia Context:\n{wikipedia_context}"
        
        user_message = f"{question}{context_text}"
        messages.append({
            "role": "user",
            "content": user_message
        })
        
        # Call Claude API via OpenRouter
        async with aiohttp.ClientSession() as session:
            headers = {
                "Authorization": f"Bearer {OPENROUTER_API_KEY}",
                "HTTP-Referer": "https://replit.com",
                "X-Title": "LiteraryBot"
            }
            
            # Generate enhanced context from literature knowledge base
            literature_context = generate_literature_context(question)
            
            payload = {
                "model": "claude-3.5-sonnet",
                "messages": messages,
                "temperature": 0.7,
                "max_tokens": 1500,
                "system": get_literature_system_prompt()
            }
            
            async with session.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=payload
            ) as resp:
                if resp.status == 200:
                    response_data = await resp.json()
                    assistant_response = response_data.get('choices', [{}])[0].get('message', {}).get('content', '')
                    
                    # Store conversation in memory
                    user_conversations[user_id].append({"role": "user", "content": question})
                    user_conversations[user_id].append({"role": "assistant", "content": assistant_response})
                    
                    # Trim memory if too long
                    if len(user_conversations[user_id]) > MAX_MEMORY:
                        user_conversations[user_id] = user_conversations[user_id][-MAX_MEMORY:]
                    
                    logger.info(f"Response generated for user {user_id}")
                    return assistant_response
                else:
                    error_data = await resp.text()
                    logger.error(f"OpenRouter API error {resp.status}: {error_data}")
                    logger.info("Falling back to offline knowledge base")
                    # Use offline knowledge base as fallback
                    offline_answer = generate_offline_answer(question)
                    
                    # Store in memory
                    user_conversations[user_id].append({"role": "user", "content": question})
                    user_conversations[user_id].append({"role": "assistant", "content": offline_answer})
                    
                    if len(user_conversations[user_id]) > MAX_MEMORY:
                        user_conversations[user_id] = user_conversations[user_id][-MAX_MEMORY:]
                    
                    return offline_answer
    
    except Exception as e:
        logger.error(f"Error generating response: {e}")
        logger.info("Falling back to offline knowledge base due to exception")
        # Use offline knowledge base as fallback
        offline_answer = generate_offline_answer(question)
        
        # Store in memory
        user_conversations[user_id].append({"role": "user", "content": question})
        user_conversations[user_id].append({"role": "assistant", "content": offline_answer})
        
        if len(user_conversations[user_id]) > MAX_MEMORY:
            user_conversations[user_id] = user_conversations[user_id][-MAX_MEMORY:]
        
        return offline_answer

def clear_user_memory(user_id: int) -> None:
    """Clear conversation history for a user"""
    if user_id in user_conversations:
        user_conversations[user_id] = []
    logger.info(f"Memory cleared for user {user_id}")
